{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7417a0f5",
   "metadata": {},
   "source": [
    "Preparing Your Data : Import ,Read and Clean Data\n",
    "The first step to data analysis is to have a look on your data before working on it, that is why you always should start with Exploratory data analysis.\n",
    "\n",
    "Exploratory data analysis means to have an insightful look into your data before working with it. It starts withstep 1: importing your data .\n",
    "\n",
    "Import Data\n",
    "\n",
    "Sometimes not all data you need to work with is in csv format. So Python provides a great opportunity to import data from various other formats to work with.\n",
    "\n",
    "First of all we import Pandas as the known alias pd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de0b1616",
   "metadata": {},
   "source": [
    "hen after that we type the code that reads the specific file of the data. There are different types of files: \n",
    "\n",
    "- flat files: which are plain text files or tables with no relational databases \n",
    "\n",
    "some of the commands are :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f03fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CSV file(from a location on your drive)\n",
    "\n",
    "data= pd.read_csv(\"C:\\\\Users\\\\Someplace\\\\Documents\\\\file1.csv\")\n",
    "\n",
    "CSV file (from a website)\n",
    "\n",
    "data = pd.read_csv(\"http://winterolympicsmedals.com/medals.csv\")\n",
    "\n",
    ".txt file\n",
    "\n",
    "data = pd.read_table(\"C:\\\\Users\\\\Someplace\\\\Desktop\\\\example2.txt\")\n",
    "\n",
    "Excel file\n",
    "\n",
    "data = pd.read_excel(\"https://www.eia.gov/dnav/pet/hist_xls/RBRTEd.xls\")\n",
    "\n",
    "SAS file\n",
    "\n",
    "data = pd.read_sas('meows.sas7bdat')\n",
    "\n",
    "STATA file\n",
    "\n",
    "data = pd.read_stata('films.dta')\n",
    "\n",
    "- Relational databases: such as SQL\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine  \n",
    "engine = create_engine('sqlite://name.sqlite' )\n",
    "or using pandas:\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT  *  FROM  Orders \" , engine)\n",
    "- Pickled files:\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('pickledname.pkl', 'rb') as file:\n",
    "    pickled_data = pickle.load(file)\n",
    "- HDF5 files:\n",
    "\n",
    "\n",
    "import h5py\n",
    "filename = 'name_file.hdf5'\n",
    "data = h5py.file(filename, 'r')\n",
    "- MATLAB files:\n",
    "\n",
    "\n",
    "import scipy.io \n",
    "filename = 'name.mat'\n",
    "mat = scipy.io.loadmat(filename)\n",
    "\n",
    "There is also a way to get the data from an HTML file called web scraping. Web scraping works through BeautifulSoup\n",
    "\n",
    "import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = ' www.something.html '\n",
    "r = request.get(url)\n",
    "html.doc = r.text\n",
    "Soup = BeautifulSoup(html.doc)\n",
    "Pretty_Soup = Soup.pretty()print(pretty_Soup)\n",
    "\n",
    "After importing the data here comes the step of reading and cleaning it.\n",
    "\n",
    "firstly we start by having a general look on the data after importing it through the known commands of pandas.\n",
    "\n",
    "\n",
    "df.head()\n",
    "df.describe()\n",
    "This step aims at understanding what is your data about and have an idea if there is any missing or duplicate data.\n",
    "\n",
    "There are various ways to deal with missing or duplicate data. You can read a hint about them in the blog post named Pandas Manipulation Techniques.\n",
    "\n",
    "\n",
    "There is another important step in reading your data which is visualizing it. It gives an idea about outlier data and you can find any inconsistencies that might hinder your data analysis process.\n",
    "\n",
    "Now after you have done all those steps your data is ready for work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
